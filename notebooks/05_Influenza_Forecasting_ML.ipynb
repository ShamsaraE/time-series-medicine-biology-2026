{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd12c8cb",
   "metadata": {},
   "source": [
    "\n",
    "# Influenza Forecasting with Machine Learning\n",
    "## Weekly Influenza Cases – Germany (RKI Data)\n",
    "\n",
    "\n",
    "---\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/ShamsaraE/time-series-medicine-biology-2026/blob/main/notebooks/05_Influenza_Forecasting_ML.ipynb)\n",
    "---\n",
    "We demonstrate:\n",
    "\n",
    "- Log transformation\n",
    "- Lag-based supervised learning\n",
    "- Ridge regression with scaling\n",
    "- Proper recursive multi-step forecasting\n",
    "- Seasonal naive baseline\n",
    "- MASE evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0679b1",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c864b",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Load and Prepare Data\n",
    "\n",
    "\n",
    "We load weekly influenza case counts from the RKI repository and:\n",
    "\n",
    "1. Filter for Germany\n",
    "2. Convert ISO week format to real dates\n",
    "3. Aggregate weekly counts\n",
    "4. Enforce weekly frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3783b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load influenza data\n",
    "url = \"https://raw.githubusercontent.com/robert-koch-institut/Influenzafaelle_in_Deutschland/main/IfSG_Influenzafaelle.tsv\"\n",
    "df = pd.read_csv(url, sep=\"\\t\")\n",
    "\n",
    "# Filter for Germany\n",
    "df = df[df[\"Region\"] == \"Deutschland\"].copy()\n",
    "\n",
    "# Convert ISO week to actual Monday date\n",
    "df[\"date\"] = pd.to_datetime(df[\"Meldewoche\"] + \"-1\", format=\"%G-W%V-%u\")\n",
    "\n",
    "# Sort and set index\n",
    "df = df.sort_values(\"date\").set_index(\"date\")\n",
    "\n",
    "# Aggregate weekly cases\n",
    "ts = df.groupby(df.index)[\"Fallzahl\"].sum().astype(float)\n",
    "\n",
    "# Ensure weekly frequency\n",
    "ts = ts.asfreq(\"W-MON\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8712d975",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Log Transformation\n",
    "\n",
    "## Definition\n",
    "Log transformation:\n",
    "\n",
    "log(1 + y)\n",
    "\n",
    "is used to stabilize variance in skewed count data.\n",
    "\n",
    "## Why?\n",
    "Epidemic peaks can vary from 0 to >100,000 cases.\n",
    "Linear regression performs better on stabilized scales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed653984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts_log = np.log1p(ts)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(ts_log)\n",
    "plt.title(\"Log-Transformed Influenza Cases\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bfd89a",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretation\n",
    "\n",
    "Variance is now more stable across seasons.\n",
    "Large peaks no longer dominate the scale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eadf687",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Lag Feature Engineering\n",
    "\n",
    "## Definition\n",
    "Lag features convert a time series into a supervised learning problem:\n",
    "\n",
    "$y_t = f(y_{t-1}, y_{t-2}, ..., y_{t-p})$\n",
    "\n",
    "## What we include\n",
    "- Short memory: lags 1, 2, 3\n",
    "- Seasonal memory: lag 52 (one year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60963ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lags = [1, 2, 3, 52]\n",
    "\n",
    "data = pd.DataFrame({\"y\": ts_log})\n",
    "\n",
    "# Create lagged features\n",
    "for lag in lags:\n",
    "    data[f\"lag{lag}\"] = data[\"y\"].shift(lag)\n",
    "\n",
    "# Remove rows with missing values\n",
    "data = data.dropna()\n",
    "\n",
    "X = data.drop(columns=\"y\")\n",
    "y = data[\"y\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ac2d45",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretation\n",
    "\n",
    "We transformed the time series into a regression dataset.\n",
    "Each row now contains past values predicting the present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3efaf18",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Train-Test Split\n",
    "\n",
    "## Definition\n",
    "Time series split must preserve temporal order.\n",
    "\n",
    "## What we do\n",
    "We reserve the last 52 weeks for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c87d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_size = 52\n",
    "\n",
    "X_train = X.iloc[:-test_size]\n",
    "X_test = X.iloc[-test_size:]\n",
    "\n",
    "y_train = y.iloc[:-test_size]\n",
    "y_test = y.iloc[-test_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d2ecf",
   "metadata": {},
   "source": [
    "\n",
    "# 6. Ridge Regression with Standardization\n",
    "\n",
    "## Definition\n",
    "Ridge regression minimizes:\n",
    "\n",
    "$||y - Xβ||² + λ||β||²$\n",
    "\n",
    "Standardization ensures features are on comparable scales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10430122",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------\n",
    "# Build a Machine Learning Pipeline\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# A Pipeline chains multiple processing steps together.\n",
    "# This ensures that scaling is applied correctly\n",
    "# during both training and prediction.\n",
    "\n",
    "model = Pipeline([\n",
    "    \n",
    "    # Step 1: Standardize features\n",
    "    # StandardScaler transforms each feature to:\n",
    "    #    (x - mean) / standard deviation\n",
    "    #\n",
    "    # Why?\n",
    "    # Ridge regression is sensitive to feature scale.\n",
    "    # Without scaling, large-magnitude lags could dominate\n",
    "    # the regularization penalty.\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    \n",
    "    \n",
    "    # Step 2: Ridge Regression\n",
    "    # Ridge minimizes:\n",
    "    #     ||y - Xβ||² + λ||β||²\n",
    "    #\n",
    "    # alpha = λ controls the strength of regularization.\n",
    "    # alpha = 1.0 is moderate shrinkage.\n",
    "    (\"ridge\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Fit the Model\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# The model learns coefficients β from the training data.\n",
    "# Only past information (X_train) is used.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# One-Step-Ahead Prediction\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# We now predict the test set.\n",
    "# These are one-step predictions because\n",
    "# each row in X_test uses true past values.\n",
    "y_pred_one = model.predict(X_test)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Evaluate Performance\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Mean Absolute Error (MAE):\n",
    "#\n",
    "# MAE = mean(|y_true - y_pred|)\n",
    "#\n",
    "# On log scale, this measures average deviation\n",
    "# in transformed space.\n",
    "mae_one = mean_absolute_error(y_test, y_pred_one)\n",
    "\n",
    "print(\"One-step MAE (log scale):\", mae_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605154a6",
   "metadata": {},
   "source": [
    "\n",
    "# 7. Recursive Multi-Step Forecasting\n",
    "\n",
    "## Definition\n",
    "Recursive forecasting feeds predictions back into the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Recursive Multi-Step Forecasting\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Definition:\n",
    "# Recursive forecasting means that predicted values\n",
    "# are fed back into the model to generate future forecasts.\n",
    "#\n",
    "# Unlike one-step forecasting, we no longer use\n",
    "# the true observed future values.\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Step 1: Initialize Forecasting History\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# We start with the FULL training history.\n",
    "# This ensures that lag52 (seasonal lag) remains valid.\n",
    "#\n",
    "# IMPORTANT:\n",
    "# We must keep at least 52 past values,\n",
    "# otherwise lag52 would not exist.\n",
    "history = list(ts_log.iloc[:-test_size].values)\n",
    "\n",
    "\n",
    "# This list will store our multi-step predictions\n",
    "recursive_preds = []\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Step 2: Iteratively Forecast Each Future Week\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# We forecast one week at a time.\n",
    "# Each new prediction is appended to history\n",
    "# and used to predict the next step.\n",
    "\n",
    "for i in range(test_size):\n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Construct Feature Vector Using Latest Available History\n",
    "    # -------------------------------------------------------\n",
    "    \n",
    "    # At time t, we build:\n",
    "    #   lag1  = y_{t-1}\n",
    "    #   lag2  = y_{t-2}\n",
    "    #   lag3  = y_{t-3}\n",
    "    #   lag52 = y_{t-52}\n",
    "    #\n",
    "    # These values may be real observations (early steps)\n",
    "    # or previous predictions (later steps).\n",
    "    features = {\n",
    "        \"lag1\": history[-1],\n",
    "        \"lag2\": history[-2],\n",
    "        \"lag3\": history[-3],\n",
    "        \"lag52\": history[-52]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Convert dictionary into DataFrame\n",
    "    # This preserves feature names expected by the pipeline\n",
    "    X_input = pd.DataFrame([features])\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Step 3: Predict Next Value\n",
    "    # -------------------------------------------------------\n",
    "    \n",
    "    # model.predict returns an array → take first element\n",
    "    pred = model.predict(X_input)[0]\n",
    "    \n",
    "    \n",
    "    # Store prediction\n",
    "    recursive_preds.append(pred)\n",
    "    \n",
    "    \n",
    "    # -------------------------------------------------------\n",
    "    # Step 4: Update History\n",
    "    # -------------------------------------------------------\n",
    "    \n",
    "    # The predicted value becomes part of the time series.\n",
    "    # Future lags will depend on this value.\n",
    "    history.append(pred)\n",
    "\n",
    "\n",
    "# Convert predictions to NumPy array\n",
    "recursive_preds = np.array(recursive_preds)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Step 5: Evaluate Recursive Forecast\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# MAE measures average absolute deviation\n",
    "# between true log-values and predicted log-values.\n",
    "mae_recursive = mean_absolute_error(y_test, recursive_preds)\n",
    "\n",
    "print(\"Recursive MAE (log scale):\", mae_recursive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15590791",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretation\n",
    "\n",
    "Recursive forecasting is significantly harder.\n",
    "Errors accumulate over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed65b26",
   "metadata": {},
   "source": [
    "\n",
    "# 8. Seasonal Naive Baseline\n",
    "\n",
    "## Definition\n",
    "Seasonal naive forecast:\n",
    "\n",
    "$ŷ_t = y_{t-52}$\n",
    "\n",
    "This is often a very strong benchmark in epidemiology.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf1bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------------------------------------\n",
    "# Seasonal Naive Baseline\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# Definition:\n",
    "# The seasonal naive forecast assumes that\n",
    "# the best prediction for this week\n",
    "# is the value observed exactly one year ago.\n",
    "#\n",
    "# Mathematically:\n",
    "#     ŷ_t = y_{t-52}\n",
    "#\n",
    "# Why 52?\n",
    "# Because influenza exhibits strong annual seasonality\n",
    "# (weekly data → 52 weeks per year).\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Step 1: Generate Seasonal Naive Forecast\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# shift(52) moves the time series forward by 52 weeks,\n",
    "# so each observation becomes aligned with the value\n",
    "# from the same week last year.\n",
    "seasonal_naive = ts_log.shift(52).iloc[-test_size:]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Step 2: Evaluate Baseline Performance\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# We compare the baseline forecast\n",
    "# with the true observed test values.\n",
    "#\n",
    "# MAE measures average absolute deviation.\n",
    "mae_naive = mean_absolute_error(y_test, seasonal_naive)\n",
    "\n",
    "print(\"Seasonal Naive MAE (log scale):\", mae_naive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee344e",
   "metadata": {},
   "source": [
    "\n",
    "# 9. MASE Evaluation\n",
    "\n",
    "## Definition\n",
    "MASE = Model MAE / Seasonal Naive MAE\n",
    "\n",
    "If MASE < 1 → model beats baseline.\n",
    "If MASE > 1 → baseline is stronger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mase = mae_recursive / mae_naive\n",
    "print(\"MASE (recursive):\", mase)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
